{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this analysis is threefold:\n",
    "1. Word association identification\n",
    "2. Contextual sentiment extraction\n",
    "3. Theme/topic assignment to word clusters\n",
    "\n",
    "The dataset used for the purpose of this analysis consists of [hotel reviews](https://code.google.com/archive/p/dataset/downloads) mined from [Tripadvisor.com](http://tripadvisor.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets load the data\n",
    "Hotel reviews are available for the cities of Beijing, Chicago, Dubai, Las-Vegas, London, Montreal, New-Delhi, New-York-City, San-Francisco and Shanghai spanning the years 2003 - 2010. For the purpose of this analysis, the city has been set to *chicago* and year to *2007*. These settings however **can** be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# Load custom module\n",
    "import helperFunctions as hf\n",
    "\n",
    "# Read Hotel Reviews Data into a data frame\n",
    "dataPath = 'OpinRankDataSet/hotels/'\n",
    "city = 'chicago'\n",
    "year = '2007'\n",
    "hotelReviewCount, reviewsDF = hf.readReviewsData(dataPath, city, year)\n",
    "print('Done reading data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clean up the text\n",
    "Cleaning mainly involves removal of noisy characters, stopwords, case normalization and stemming. A mapping is also created between words and their stemmed forms, so that extracting the actual word is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined reviews corpus from all reviews for different applications\n",
    "combinedCorpus = reviewsDF['FullReview'].str.cat(sep=' ')\n",
    "corpusOnlyChar = hf.preprocessText(combinedCorpus,onlyChar=True,lower=True,stopw=False,stem=False)\n",
    "corpusNoStop   = hf.preprocessText(corpusOnlyChar,onlyChar=False,lower=False,stopw=True,stem=False)\n",
    "corpusStem     = hf.preprocessText(corpusNoStop,onlyChar=False,lower=False,stopw=False,stem=True)\n",
    "print('Done corpus processing')\n",
    "\n",
    "# Create the unstem dictionary for the corpus\n",
    "unstemDict = {}\n",
    "corpusTrim = np.array(corpusNoStop.split())\n",
    "hf.unstem(corpusTrim,unstemDict)\n",
    "corpusTrim = list(corpusTrim)\n",
    "print('Done creating unstem dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick look at the most frequent terms in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find Similar Words (appearing in similar contexts)\n",
    "from nltk import ContextIndex\n",
    "corpusOnlyChar = hf.preprocessText(combinedCorpus,onlyChar=True,lower=True,stopw=False,stem=False)\n",
    "reviewContextFull3W = ContextIndex(tokens=corpusOnlyChar.split(),context_func=hf.contextFunc3W)\n",
    "reviewContextFull2W = ContextIndex(tokens=corpusOnlyChar.split(),context_func=hf.contextFunc2W)\n",
    "reviewContextStop2W = ContextIndex(tokens=corpusNoStop.split(),context_func=hf.contextFunc2W)\n",
    "word = 'suite'\n",
    "similarWords = hf.getSimilarWords(word, reviewContextFull3W, reviewContextFull2W, reviewContextStop2W, numWords=20)\n",
    "print('Done finding similar words')\n",
    "\n",
    "# Find Collocated Words (words appearing together in a phrase)\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "windowSize = 3\n",
    "finder = BigramCollocationFinder.from_words(corpusStem.split(), windowSize)\n",
    "collocationWords = hf.getCollocatedWords(finder,unstemDict,numPairs=10)\n",
    "print('Done Finding Collocated words')\n",
    "\n",
    "# Find Contextual Sentiments\n",
    "reviewsDF['cleanReview'] = reviewsDF['FullReview'].apply(hf.preprocessText)\n",
    "mostFreqWords = hf.getMostFrequentWords(reviewsDF['cleanReview'],unstemDict,5)\n",
    "posTaggedWords = nltk.pos_tag(list(mostFreqWords.index))\n",
    "hotelWords = [w for w,tag in posTaggedWords if tag == 'NN']\n",
    "reviewSentiments = hf.getContextualSentiment(reviewsDF['FullReview'][1], domainWords = hotelWords)\n",
    "print('Done building sentiment analyzer')\n",
    "\n",
    "# Get similar word clusters along with topic\n",
    "cleanReview = reviewsDF['FullReview'].apply(hf.preprocessText,stopw=True,minLen = False)\n",
    "cleanReview = cleanReview.str.cat(sep=' ')\n",
    "maxClusters = 10\n",
    "clusterDict = hf.getThemeClusters(cleanReview,mostFreqWords,unstemDict,maxClusters)\n",
    "print('Done clustering similar terms and assigning topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the most frequent words (excluding stopwords)\n",
    "cleanReview = reviewsDF['FullReview'].apply(hf.preprocessText)\n",
    "mostFreqWords = hf.getMostFrequentWords(cleanReview,unstemDict,5)\n",
    "print('Here is a list of the top-most occurring words in the corpus:')\n",
    "mostFreqWords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('wordcloud')\n",
    "!python wordcloud/setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Association\n",
    "\n",
    "Although word association has many connotations, it can be broadly classified into two types:\n",
    "1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
